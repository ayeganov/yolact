#!/usr/bin/env python
'''
This modules serves the application responsible for routing events from ROS to
the DNN process running in Python 3.
'''
import abc
import argparse
import functools
import logging
import signal
import sys
import time
import traceback

from logzero import logger
from tornado import ioloop, gen
import cv2
import munch
import logzero
import numpy as np
import torch

from image_pb2 import Detection, NetOutput
from netpool import NetworkProcessPool
import comm
import wraploop


LOG_LEVELS = {
    "warn": logging.WARNING,
    "error": logging.ERROR,
    "info": logging.INFO,
    "debug": logging.DEBUG,
    "critical": logging.CRITICAL,
    "fatal": logging.FATAL
}


class FactoryException(Exception):
    '''
    Raise when trying to create an unknown entity
    '''


class Collector(metaclass=abc.ABCMeta):
    '''
    This defines the interface for the collector objects that make a decision
    when to run the inference.

    The interface consists of two main methods:
        collect - contains the logic to accept new incoming data
        ready_to_infer - contains the logic to decide when enough is data
                         collected to run the inference
    '''
    @abc.abstractmethod
    def collect(self, source, data):
        '''
        Add new data point to this collector

        @param source - a unique string indicating the source of this data. IE: Camera FL, Camera FR etc
        @param data - data this collector is assembling, image, lidar point cloud, radar etc
        '''

    @abc.abstractproperty
    def is_ready_to_infer(self):
        '''
        Analyze the data collected so far and return True if there is enough to
        run inference, False otherwise.
        '''

    @abc.abstractmethod
    def run_inference(self, network):
        '''
        Transform the data collected so far and run the inference

        @param network - network on which to run the inference with the collected data
        @returns result of the inference
        '''


class BatchCollector(Collector):
    '''
    Collect data coming from the receiver, concatenate them and run through the network inference
    '''
    def __init__(self, sources, loop):
        '''
        Initialize a new instance of the Collector

        @param sources - a set containing unique strings representing data sources
        @param loop - instance IOLoop
        '''
        self._sources = sources
        self._loop = loop
        self._latest_data = {}
        self._future_inference = None
        self._running_inference = False

    @property
    def is_ready_to_infer(self):
        '''
        Check if all images have been received, and can be run through the inference.
        True if images ready and inference is not being run right now, False otherwise.
        '''
        all_sources_provided_data = all(s in self._latest_data for s in self._sources)
        return not self._running_inference and all_sources_provided_data

    def collect(self, source, datum):  # pylint: disable=arguments-differ
        '''
        Collect the datum from the provided source
        '''
        self._latest_data[source] = datum

    async def run_inference(self, network):
        '''
        Execute the inference on the provided network

        @param network - an instance of subclass of Network. It will run the
                         inference on the collected data.
        @return network inference results
        '''
        self._running_inference = True
        images = list(self._latest_data.values())
        self._latest_data.clear()

        result = await network.submit(images)
        self._running_inference = False
        return result


def create_collector(collector_conf, sources, loop):
    '''
    Given the type of the collector create an appropriate collector instance

    @param collector_type - string representing the collector to be created
    @returns subclass of Collector
    @raises FactoryException
    '''
    collector_type = collector_conf.type
    logger.info("Creating collector: %s", collector_type)
    if collector_type == BatchCollector.__name__:
        return BatchCollector(sources, loop)
    raise FactoryException("Unknown collector type: {}".format(collector_type))


def display_result(net_output):
    output = NetOutput()
    output .ParseFromString(net_output)

    proto = Detection()
    proto.ParseFromString(output.output[0])
    mask_img = np.frombuffer(proto.mask, dtype=np.dtype("uint8")).reshape(proto.width, proto.height)
    logger.debug("Got result %s", proto.sequence_num)

    cv2.imshow("Net Pool", mask_img)
    cv2.waitKey(1)


class InferenceController(object):
    '''
    This class is responsible for receiving images on ZMQ subscriber sockets,
    running the inference through YOLACT and publishing the results over ZMQ.
    '''
    def __init__(self, config, loop):
        '''
        Initialize a new instance of ZmqImageReceiver

        @param config - configuration of the controller
        @param loop - instance of tornado loop
        '''
        self._config = config
        self._loop = loop
        self._zmq_topics = set()
        self._collector = create_collector(config.collector, config.sources, loop)
        self._network_pool = NetworkProcessPool(config.network, queue_size=9, loop=loop)
        self._source_cons = []
        self._sink_cons = []

    async def _handle_data(self, source, message):
        '''
        Collect the data from the given source
        '''
        self._collector.collect(source, message)

        if self._collector.is_ready_to_infer and self._network_pool.is_ready:
            net_output = await self._collector.run_inference(self._network_pool)

            # TODO: Remove next line, it is there only for demonstration purpose only
            self._loop.add_callback(display_result, net_output)
            await self._loop.run_in_executor(None, self._sink_output, net_output)
        else:
            logger.warn("Dropping messages because collector or network is not ready")

    def _sink_output(self, net_output):
        '''
        Send the output to all of the configured sink sockets

        @param net_output - serialized output of the network
        '''
        logger.debug("Sending the data back to beyond")
        for zmq_sock in self._sink_cons:
            zmq_sock.send(net_output)

    def initialize_connections(self):
        '''
        Create and initialize all ROS and ZMQ connections
        '''
        logger.info("Initializing InferenceController")

        def msg_handler(source, msg):
            '''handle incoming data'''
            try:
                self._loop.add_callback(self._handle_data, source, msg[0])
            except Exception as error:  # pylint: disable=broad-except
                logger.exception(error)

        for source in self._config.sources:
            callback = functools.partial(msg_handler, source)
            zmq_sub = comm.sub_to_zmq(source, callback, self._loop)
            self._source_cons.append(zmq_sub)

        self._sink_cons = [comm.pub_to_zmq(sink) for sink in self._config.sinks]

    def shutdown(self):
        '''
        Shutdown this proxy
        '''
        logger.info("Calling shutdown")
        self._network_pool.shutdown()
        for zmq_con in self._source_cons:
            logger.info("Closing zmq connection from beyond")
            zmq_con.close()

        for zmq_con in self._sink_cons:
            logger.info("Closing zmq connection to beyond")
            zmq_con.close()


DESCRIPTION = '''
Inferencer receives the network input data through ZMQ and runs configured
network. The results get published back to beyond through the sink.
'''


def interrupt_handler(signal_id, _, loop, control):
    '''
    Handles the SIGINT interrupt

    @param loop - tornado ioloop
    @param signal_id - signal id that caused this interrupt(SIGINT)
    @param _ - current stack frame
    @param control - InferenceController instance
    '''
    try:
        logger.info("Received signal 'SIGINT:%s', shutting down...", signal_id)
        loop.add_callback_from_signal(control.shutdown)
        loop.add_callback_from_signal(loop.stop)
    except Exception as error:  # pylint: disable=broad-except
        logger.exception(error)
        sys.exit(1)


async def executor_test(loop, netpool):
#    sleep_time = np.random.randint(5)

    def sleep_some(sleep_time):
        print("going to sleep for {} seconds".format(sleep_time))
        time.sleep(sleep_time)
        print("ooah, awake after {} seconds".format(sleep_time))

    logger.info("Submitting work")
    data = [bytes([c]) for c in range(3)]
#    future = loop.run_in_executor(None, sleep_some, sleep_time)
    await netpool.submit(data)
#    await future


def main():
    '''main, whatcha want?'''
    parser = argparse.ArgumentParser(description=DESCRIPTION)
    parser.add_argument("-c",
                        "--config",
                        help="Config file containing the pipeline settings",
                        type=argparse.FileType("r"),
                        required=True)

    parser.add_argument("-l",
                        "--log",
                        help="Log file path",
                        default="inferencer.log",
                        type=str)
    parser.add_argument("-v",
                        "--level",
                        default="info",
                        choices=["info", "warn", "fatal", "error", "critical", "debug"])

    args = parser.parse_args()

    if args.log is not None:
        logzero.logfile(args.log, maxBytes=1e7)
        logzero.loglevel(LOG_LEVELS[args.level])

    config = munch.Munch.fromYAML(args.config)

    loop = ioloop.IOLoop.instance()
    control = InferenceController(config, loop)
    interrupt_partial = functools.partial(interrupt_handler, loop=loop, control=control)

    signal.signal(signal.SIGINT, interrupt_partial)
    signal.signal(signal.SIGTERM, interrupt_partial)

    @wraploop.eventloop
    @gen.coroutine
    def run_proxy(_):
        '''
        Run the server
        '''
        logger.info("Started ZMQ Inferencer")
        control.initialize_connections()

        return 0

    ret_code = run_proxy(loop)
    sys.exit(ret_code)


if __name__ == "__main__":
    main()
